{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title NN classifier for Political Bias using bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103262\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/source/newsclust.csv\")\n",
    "df = df.query(\"site != 'cbn.com'\")\n",
    "print(len(df))\n",
    "df = df.sample(90000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the bias for each one of the articles, based on the publication's known bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21014</td>\n",
       "      <td>2015-03-05T19:51:00.000+02:00</td>\n",
       "      <td>washingtonexaminer.com</td>\n",
       "      <td>A closer look at sick leave By Sean Higgins | ...</td>\n",
       "      <td>A closer look at sick leave</td>\n",
       "      <td>http://www.washingtonexaminer.com/a-closer-loo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52696</td>\n",
       "      <td>2016-11-07T20:30:00.000+02:00</td>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td>What to Do About Russia’s Hacking \\nWeaker tha...</td>\n",
       "      <td>What to Do About Russia’s Hacking</td>\n",
       "      <td>https://www.bloomberg.com/view/articles/2016-1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           date                    site  \\\n",
       "0       21014  2015-03-05T19:51:00.000+02:00  washingtonexaminer.com   \n",
       "1       52696  2016-11-07T20:30:00.000+02:00           bloomberg.com   \n",
       "\n",
       "                                                text  \\\n",
       "0  A closer look at sick leave By Sean Higgins | ...   \n",
       "1  What to Do About Russia’s Hacking \\nWeaker tha...   \n",
       "\n",
       "                               title  \\\n",
       "0        A closer look at sick leave   \n",
       "1  What to Do About Russia’s Hacking   \n",
       "\n",
       "                                                 url  bias  \n",
       "0  http://www.washingtonexaminer.com/a-closer-loo...     4  \n",
       "1  https://www.bloomberg.com/view/articles/2016-1...     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bias import Bias\n",
    "\n",
    "num_classes = 7\n",
    "df['bias'] = df.apply(lambda row: Bias.get_bias_for_domain(row['site']).value, axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82297\n",
      "7703\n"
     ]
    }
   ],
   "source": [
    "TEST_DOMAINS =  {\n",
    "    'bloomberg.com',\n",
    "     'breitbart.com',\n",
    "     'c-span.org',\n",
    "     'chicagotribune.com',\n",
    "     'chron.com'\n",
    "}\n",
    "df_train =  df.loc[~df['site'].isin(TEST_DOMAINS)]\n",
    "df_test =  df.loc[df['site'].isin(TEST_DOMAINS)]\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text of the articles, create a vocabulary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import textacy\n",
    "from textacy import vsm\n",
    "\n",
    "def get_terms_list(corpus):\n",
    "    return (doc.to_terms_list(ngrams=1, named_entities=True, as_strings=True) for doc in corpus)\n",
    "\n",
    "def get_doc_term_matrix(corpus):\n",
    "    vectorizer = vsm.Vectorizer(\n",
    "                     weighting='tfidf', normalize=True, smooth_idf=True,\n",
    "                     min_df=3, max_df=0.95, max_n_terms=100000)\n",
    "    terms_list = get_terms_list(corpus)\n",
    "    doc_term_matrix = vectorizer.fit_transform(terms_list)\n",
    "    return vectorizer, terms_list, doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_trn = textacy.Corpus('en', texts=df_train['title'].astype(str).__iter__())\n",
    "corpus_test = textacy.Corpus('en', texts=df_test['title'].astype(str).__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82297, 19399) (7703, 19399)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<82297x19399 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 666649 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer, terms_list, doc_term_matrix_trn = get_doc_term_matrix(corpus_trn)\n",
    "doc_term_matrix_test = vectorizer.transform(get_terms_list(corpus_test))\n",
    "term_count = doc_term_matrix_trn.shape[1]\n",
    "print(doc_term_matrix_trn.shape, doc_term_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.52813461,  0.4330626 ,  0.55988023, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = doc_term_matrix_trn.todense()\n",
    "test = doc_term_matrix_test.todense()\n",
    "trn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Hidden Layer NN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force use CPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model = Sequential([\n",
    "    Dense(25, input_shape=(term_count,), activation='relu'),\n",
    "    # Dense(50, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(7, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "# k_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82297 samples, validate on 7703 samples\n",
      "Epoch 1/2\n",
      "82297/82297 [==============================] - 45s - loss: 1.4630 - acc: 0.4644 - val_loss: 1.4360 - val_acc: 0.5339\n",
      "Epoch 2/2\n",
      "82297/82297 [==============================] - 43s - loss: 1.0843 - acc: 0.6050 - val_loss: 1.4638 - val_acc: 0.4705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x4c7a39780>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "labels_train = np.array(df_train['bias'])\n",
    "labels_test = np.array(df_test['bias'])\n",
    "\n",
    "k_model.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This actually reduces the validation accuracy\n",
    "# Train on 82297 samples, validate on 7703 samples\n",
    "# Epoch 1/1\n",
    "# 82297/82297 [==============================] - 46s - loss: 1.0174 - acc: 0.6303 - val_loss: 1.4829 - val_acc: 0.4362\n",
    "#\n",
    "# k_model.optimizer.lr.assign(0.0001)\n",
    "# k_model.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually verify some articles. The bias for these articles should match the predicted bias below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>title</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>c-span.org</td>\n",
       "      <td>Katrina 10 Years Later Representative Stephani...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>breitbart.com</td>\n",
       "      <td>Stephen A. Smith on Kurt Busch: Double Standar...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>c-span.org</td>\n",
       "      <td>C-SPAN TV Schedule | C-SPAN.org</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td>GM China Venture Said to Be Under Government A...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25719</th>\n",
       "      <td>chron.com</td>\n",
       "      <td>Wednesday's Sports Transactions - Houston Chro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                site                                              title  bias\n",
       "24342     c-span.org  Katrina 10 Years Later Representative Stephani...     3\n",
       "1679   breitbart.com  Stephen A. Smith on Kurt Busch: Double Standar...     5\n",
       "5705      c-span.org                    C-SPAN TV Schedule | C-SPAN.org     3\n",
       "7810   bloomberg.com  GM China Venture Said to Be Under Government A...     2\n",
       "25719      chron.com  Wednesday's Sports Transactions - Houston Chro...     2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df_test.sample(5)\n",
    "df_sample[['site', 'title', 'bias']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  47.0466052187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigo/pytorch/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>title</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>c-span.org</td>\n",
       "      <td>Katrina 10 Years Later Representative Stephani...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>breitbart.com</td>\n",
       "      <td>Stephen A. Smith on Kurt Busch: Double Standar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>c-span.org</td>\n",
       "      <td>C-SPAN TV Schedule | C-SPAN.org</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td>GM China Venture Said to Be Under Government A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25719</th>\n",
       "      <td>chron.com</td>\n",
       "      <td>Wednesday's Sports Transactions - Houston Chro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                site                                              title  bias\n",
       "24342     c-span.org  Katrina 10 Years Later Representative Stephani...     5\n",
       "1679   breitbart.com  Stephen A. Smith on Kurt Busch: Double Standar...     1\n",
       "5705      c-span.org                    C-SPAN TV Schedule | C-SPAN.org     3\n",
       "7810   bloomberg.com  GM China Venture Said to Be Under Government A...     4\n",
       "25719      chron.com  Wednesday's Sports Transactions - Houston Chro...     2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(k_model.predict(test), axis=1)\n",
    "print(\"precision = \", np.sum(predictions == labels_test) * 100.0 / len(labels_test))\n",
    "corpus_sample = textacy.Corpus('en', texts=df_sample['title'].astype(str).__iter__())\n",
    "sample = vectorizer.transform(get_terms_list(corpus_sample)).todense()\n",
    "df_prediction, df_prediction['bias'] = df_sample[['site', 'title']], np.argmax(k_model.predict(sample), axis=1)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,  503, 2848,  705,  565,  429,   29],\n",
       "       [   0,  470,   74,  206,   29,  247,    3],\n",
       "       [   0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,  573,  264,   42,   64,  570,   80],\n",
       "       [   0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(labels_test, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11dbbc0b8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
