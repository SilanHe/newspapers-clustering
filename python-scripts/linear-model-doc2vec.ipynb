{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a document vector linear classifier using Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where the JSON files are located\n",
    "source = '../data/source/part-00000-*.json'\n",
    "# Where the processed data will be stored\n",
    "features_directory = '../data/text-spacy-features-original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner', 'tensorizer'])\n",
    "nlp.pipeline # this should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(texts):\n",
    "    docs = [doc for doc in nlp.pipe(texts, batch_size=500, n_threads=8)]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_df_from_json_files():\n",
    "    all_dfs = []\n",
    "    for filename in glob.glob(source):\n",
    "        print('Parsing file {}'.format(filename))\n",
    "        df = read_df(filename)\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    # Merge all daframes together\n",
    "    df = pd.concat(all_dfs)\n",
    "    # It takes about 15 seconds per month in my laptop\n",
    "    df['doc'] = tokenize_text(df['text'])\n",
    "    \n",
    "    df['bias'] = df['bias'].astype(str)\n",
    "    \n",
    "    # Change bias type to string (avoid issue with sklearn not knowing some datatypes when measuring precision)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def filename_root(filename):\n",
    "    filename_no_path = os.path.basename(filename)\n",
    "    return features_directory + '/' + filename_no_path\n",
    "\n",
    "def read_df(filename):\n",
    "    df = pd.read_pickle(filename_root(filename) + '.df_site_text_bias.pickle.gz', compression=\"gzip\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file ../data/source/part-00000-fdfd9a6e-3c71-4540-91f5-559870381531.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>thread.site</th>\n",
       "      <th>text</th>\n",
       "      <th>bias</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a2547fd206cf2d182e7f58131b0445e5041be533</td>\n",
       "      <td>washingtonexaminer.com</td>\n",
       "      <td>Class action filed over United’s ‘low fare gua...</td>\n",
       "      <td>Bias.RIGHT_CENTER</td>\n",
       "      <td>(Class, action, filed, over, United, ’s, ‘, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e8a766deb69148bd1a840d3353d10a3d1d4590a</td>\n",
       "      <td>nydailynews.com</td>\n",
       "      <td>Jupiterimages/Getty Images/Goodshoot RF Snuggl...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "      <td>(Jupiterimages, /, Getty, Images, /, Goodshoot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7c14e6606642ecc8c1394458ff1cdf19fda06d06</td>\n",
       "      <td>youngcons.com</td>\n",
       "      <td>Cops have been getting a lot of negative atten...</td>\n",
       "      <td>Bias.RIGHT</td>\n",
       "      <td>(Cops, have, been, getting, a, lot, of, negati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608b600a0148d8257145aebb8a29c12199580d01</td>\n",
       "      <td>youngcons.com</td>\n",
       "      <td>Powered by Starbox \\nIn the social media satur...</td>\n",
       "      <td>Bias.RIGHT</td>\n",
       "      <td>(Powered, by, Starbox, \\n, In, the, social, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f94ff5791ae401d509689e8645c59f91cb8bfc15</td>\n",
       "      <td>nj.com</td>\n",
       "      <td>View/Post Comments 2013 Star-Ledger file photo...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "      <td>(View, /, Post, Comments, 2013, Star, -, Ledge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       uuid             thread.site  \\\n",
       "0  a2547fd206cf2d182e7f58131b0445e5041be533  washingtonexaminer.com   \n",
       "1  6e8a766deb69148bd1a840d3353d10a3d1d4590a         nydailynews.com   \n",
       "2  7c14e6606642ecc8c1394458ff1cdf19fda06d06           youngcons.com   \n",
       "3  608b600a0148d8257145aebb8a29c12199580d01           youngcons.com   \n",
       "4  f94ff5791ae401d509689e8645c59f91cb8bfc15                  nj.com   \n",
       "\n",
       "                                                text               bias  \\\n",
       "0  Class action filed over United’s ‘low fare gua...  Bias.RIGHT_CENTER   \n",
       "1  Jupiterimages/Getty Images/Goodshoot RF Snuggl...   Bias.LEFT_CENTER   \n",
       "2  Cops have been getting a lot of negative atten...         Bias.RIGHT   \n",
       "3  Powered by Starbox \\nIn the social media satur...         Bias.RIGHT   \n",
       "4  View/Post Comments 2013 Star-Ledger file photo...   Bias.LEFT_CENTER   \n",
       "\n",
       "                                                 doc  \n",
       "0  (Class, action, filed, over, United, ’s, ‘, lo...  \n",
       "1  (Jupiterimages, /, Getty, Images, /, Goodshoot...  \n",
       "2  (Cops, have, been, getting, a, lot, of, negati...  \n",
       "3  (Powered, by, Starbox, \\n, In, the, social, me...  \n",
       "4  (View, /, Post, Comments, 2013, Star, -, Ledge...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = build_df_from_json_files()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_invalid_token(token):\n",
    "    return token.is_punct or token.is_space or token.like_url or token.like_num or token.is_digit\n",
    "\n",
    "def get_words(doc):\n",
    "    return [token.orth_ for token in doc if not is_invalid_token(token)]\n",
    "\n",
    "def taggedDocument(doc, bias):\n",
    "    return gensim.models.doc2vec.TaggedDocument(get_words(doc), [bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ([Class, action, filed, over, United, ’s, low,...\n",
       "1    ([Jupiterimages, Getty, Images, Goodshoot, RF,...\n",
       "2    ([Cops, have, been, getting, a, lot, of, negat...\n",
       "3    ([Powered, by, Starbox, In, the, social, media...\n",
       "4    ([View, Post, Comments, Star, Ledger, file, ph...\n",
       "Name: tagged_doc, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tagged_doc'] = df.apply(lambda row: taggedDocument(row['doc'], row['bias']), axis=1)\n",
    "df['tagged_doc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DOMAINS =  {\n",
    "    'bloomberg.com',\n",
    "     'breitbart.com',\n",
    "     'c-span.org',\n",
    "     'chicagotribune.com',\n",
    "     'chron.com'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train =  df.loc[~df['thread.site'].isin(TEST_DOMAINS)]\n",
    "df_valid =  df.loc[df['thread.site'].isin(TEST_DOMAINS)]\n",
    "\n",
    "train_corpus = df_train['tagged_doc']\n",
    "valid_corpus = df_valid.apply(lambda row: get_words(row['doc']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, iter=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 3.55 s, total: 3min\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79158212"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df['bias'].values)\n",
    "\n",
    "def make_X_Y(docs_words, biases):\n",
    "    X = [model.infer_vector(words) for words in docs_words]\n",
    "    Y = encoder.transform(biases)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_words = [tagged_words.words for tagged_words in train_corpus]\n",
    "X_train, Y_train = make_X_Y(train_words, df_train['bias'].values)\n",
    "X_valid, Y_valid = make_X_Y(valid_corpus, df_valid['bias'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigo/pytorch/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>thread.site</th>\n",
       "      <th>text</th>\n",
       "      <th>bias</th>\n",
       "      <th>doc</th>\n",
       "      <th>tagged_doc</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fef6237649701e532f2259233761d97f66750cc3</td>\n",
       "      <td>chron.com</td>\n",
       "      <td>Assembly Republicans launch their election cam...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "      <td>(Assembly, Republicans, launch, their, electio...</td>\n",
       "      <td>([Assembly, Republicans, launch, their, electi...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>58d57269304c0263c9b46ac5b3a4282f9e994f65</td>\n",
       "      <td>chron.com</td>\n",
       "      <td>Rio Rancho 98, Rio Grande 62 Santa Fe 50, Capi...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "      <td>(Rio, Rancho, 98, ,, Rio, Grande, 62, Santa, F...</td>\n",
       "      <td>([Rio, Rancho, Rio, Grande, Santa, Fe, Capital...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>46d5b0fbab2fbd193c8dd82372a7513a3e51ddaa</td>\n",
       "      <td>chron.com</td>\n",
       "      <td>Arizona Charter Academy 53, Mayer 22 Chandler ...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "      <td>(Arizona, Charter, Academy, 53, ,, Mayer, 22, ...</td>\n",
       "      <td>([Arizona, Charter, Academy, Mayer, Chandler, ...</td>\n",
       "      <td>Bias.EXTREME_RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7b6bd4746b80570f30b5caeb9f09447882a88363</td>\n",
       "      <td>breitbart.com</td>\n",
       "      <td>Ingraham: GOP Establishment Now ‘Firmly Entren...</td>\n",
       "      <td>Bias.RIGHT</td>\n",
       "      <td>(Ingraham, :, GOP, Establishment, Now, ‘, Firm...</td>\n",
       "      <td>([Ingraham, GOP, Establishment, Now, Firmly, E...</td>\n",
       "      <td>Bias.EXTREME_RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>fad0e219cca7c610abcf88850f40a183d12b843b</td>\n",
       "      <td>chicagotribune.com</td>\n",
       "      <td>Welcome to the most comprehensive suburban cov...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "      <td>(Welcome, to, the, most, comprehensive, suburb...</td>\n",
       "      <td>([Welcome, to, the, most, comprehensive, subur...</td>\n",
       "      <td>Bias.LEFT_CENTER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        uuid         thread.site  \\\n",
       "23  fef6237649701e532f2259233761d97f66750cc3           chron.com   \n",
       "36  58d57269304c0263c9b46ac5b3a4282f9e994f65           chron.com   \n",
       "38  46d5b0fbab2fbd193c8dd82372a7513a3e51ddaa           chron.com   \n",
       "44  7b6bd4746b80570f30b5caeb9f09447882a88363       breitbart.com   \n",
       "48  fad0e219cca7c610abcf88850f40a183d12b843b  chicagotribune.com   \n",
       "\n",
       "                                                 text              bias  \\\n",
       "23  Assembly Republicans launch their election cam...  Bias.LEFT_CENTER   \n",
       "36  Rio Rancho 98, Rio Grande 62 Santa Fe 50, Capi...  Bias.LEFT_CENTER   \n",
       "38  Arizona Charter Academy 53, Mayer 22 Chandler ...  Bias.LEFT_CENTER   \n",
       "44  Ingraham: GOP Establishment Now ‘Firmly Entren...        Bias.RIGHT   \n",
       "48  Welcome to the most comprehensive suburban cov...  Bias.LEFT_CENTER   \n",
       "\n",
       "                                                  doc  \\\n",
       "23  (Assembly, Republicans, launch, their, electio...   \n",
       "36  (Rio, Rancho, 98, ,, Rio, Grande, 62, Santa, F...   \n",
       "38  (Arizona, Charter, Academy, 53, ,, Mayer, 22, ...   \n",
       "44  (Ingraham, :, GOP, Establishment, Now, ‘, Firm...   \n",
       "48  (Welcome, to, the, most, comprehensive, suburb...   \n",
       "\n",
       "                                           tagged_doc                pred  \n",
       "23  ([Assembly, Republicans, launch, their, electi...    Bias.LEFT_CENTER  \n",
       "36  ([Rio, Rancho, Rio, Grande, Santa, Fe, Capital...    Bias.LEFT_CENTER  \n",
       "38  ([Arizona, Charter, Academy, Mayer, Chandler, ...  Bias.EXTREME_RIGHT  \n",
       "44  ([Ingraham, GOP, Establishment, Now, Firmly, E...  Bias.EXTREME_RIGHT  \n",
       "48  ([Welcome, to, the, most, comprehensive, subur...    Bias.LEFT_CENTER  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['pred'] = encoder.inverse_transform(classifier.predict(X_valid))\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.228005865103\n",
      "Accuracy = 0.395209580838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Precision = %s\" % precision_score(df_valid['bias'], df_valid['pred'], average='macro'))\n",
    "print(\"Accuracy = %s\" % accuracy_score(df_valid['bias'].values, df_valid['pred'].values))\n",
    "# print(\"Recall = %s\" % recall_score(df_valid['bias'].values, df_valid['pred'].values)) TODO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23      Bias.LEFT_CENTER\n",
       "36      Bias.LEFT_CENTER\n",
       "38    Bias.EXTREME_RIGHT\n",
       "44    Bias.EXTREME_RIGHT\n",
       "48      Bias.LEFT_CENTER\n",
       "Name: pred, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['pred'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
