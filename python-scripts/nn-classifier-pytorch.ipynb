{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text NN classifier for Political Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigo/Libs/torchsample/torchsample/datasets.py:16: UserWarning: Cant import nibabel.. Cant load brain images\n",
      "  warnings.warn('Cant import nibabel.. Cant load brain images')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "from torchsample.initializers import XavierUniform, Uniform\n",
    "from torchsample.modules import ModuleTrainer\n",
    "from torchsample.metrics import CategoricalAccuracy\n",
    "\n",
    "%aimport torchsample.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103262\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/source/newsclust.csv\")\n",
    "df = df.query(\"site != 'cbn.com'\")\n",
    "print(len(df))\n",
    "df = df.sample(30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the bias for each one of the articles, based on the publication's known bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69135</th>\n",
       "      <td>69135</td>\n",
       "      <td>2017-02-04T09:57:00.000+02:00</td>\n",
       "      <td>motherjones.com</td>\n",
       "      <td>US Customs Agents Just Gave Airlines the Green...</td>\n",
       "      <td>US Customs Agents Just Gave Airlines the Green...</td>\n",
       "      <td>http://www.motherjones.com/politics/2017/02/us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80070</th>\n",
       "      <td>80070</td>\n",
       "      <td>2016-07-06T05:24:00.000+03:00</td>\n",
       "      <td>rightwingnews.com</td>\n",
       "      <td>Print this article Font size - 16 + 1 Subscrib...</td>\n",
       "      <td>BREAKING: FBI Director Facing Congressional Pr...</td>\n",
       "      <td>http://rightwingnews.com/top-news/breaking-fbi...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                           date               site  \\\n",
       "69135       69135  2017-02-04T09:57:00.000+02:00    motherjones.com   \n",
       "80070       80070  2016-07-06T05:24:00.000+03:00  rightwingnews.com   \n",
       "\n",
       "                                                    text  \\\n",
       "69135  US Customs Agents Just Gave Airlines the Green...   \n",
       "80070  Print this article Font size - 16 + 1 Subscrib...   \n",
       "\n",
       "                                                   title  \\\n",
       "69135  US Customs Agents Just Gave Airlines the Green...   \n",
       "80070  BREAKING: FBI Director Facing Congressional Pr...   \n",
       "\n",
       "                                                     url  bias  \n",
       "69135  http://www.motherjones.com/politics/2017/02/us...     1  \n",
       "80070  http://rightwingnews.com/top-news/breaking-fbi...     6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bias import Bias\n",
    "\n",
    "num_classes = 7\n",
    "df['bias'] = df.apply(lambda row: Bias.get_bias_for_domain(row['site']).value, axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text of the articles, create a vocabulary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "nlp.pipeline = []\n",
    "\n",
    "def tokenize_text(texts):\n",
    "    docs = [doc for doc in nlp.pipe(texts, batch_size=500, n_threads=8)]\n",
    "    return docs\n",
    "\n",
    "def is_invalid_token(token):\n",
    "    return token.is_punct or token.is_space or token.like_url or token.like_num or token.is_digit\n",
    "\n",
    "def get_words_for_docs(docs):\n",
    "    return [get_words_ids(doc) for doc in docs]\n",
    "\n",
    "def get_words_ids(doc):\n",
    "    return [token.orth for token in doc if not is_invalid_token(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['docs'] = tokenize_text(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>bias</th>\n",
       "      <th>docs</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69135</th>\n",
       "      <td>69135</td>\n",
       "      <td>2017-02-04T09:57:00.000+02:00</td>\n",
       "      <td>motherjones.com</td>\n",
       "      <td>US Customs Agents Just Gave Airlines the Green...</td>\n",
       "      <td>US Customs Agents Just Gave Airlines the Green...</td>\n",
       "      <td>http://www.motherjones.com/politics/2017/02/us...</td>\n",
       "      <td>1</td>\n",
       "      <td>(US, Customs, Agents, Just, Gave, Airlines, th...</td>\n",
       "      <td>[884, 643643, 382300, 985, 488862, 383694, 501...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                           date             site  \\\n",
       "69135       69135  2017-02-04T09:57:00.000+02:00  motherjones.com   \n",
       "\n",
       "                                                    text  \\\n",
       "69135  US Customs Agents Just Gave Airlines the Green...   \n",
       "\n",
       "                                                   title  \\\n",
       "69135  US Customs Agents Just Gave Airlines the Green...   \n",
       "\n",
       "                                                     url  bias  \\\n",
       "69135  http://www.motherjones.com/politics/2017/02/us...     1   \n",
       "\n",
       "                                                    docs  \\\n",
       "69135  (US, Customs, Agents, Just, Gave, Airlines, th...   \n",
       "\n",
       "                                                   words  \n",
       "69135  [884, 643643, 382300, 985, 488862, 383694, 501...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words'] = get_words_for_docs(df['docs'])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the most common words as vocabulary, replace the words out of vocabulary by the least frequently used word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(501, 763159), (504, 422005), (510, 382775), (512, 338685), (506, 337060)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab_size = 5000\n",
    "\n",
    "def flatten(l):\n",
    "    flat_list = [item for sublist in l for item in sublist]\n",
    "    return flat_list\n",
    "\n",
    "word_freq = Counter(flatten(df['words']))\n",
    "common_words = word_freq.most_common(vocab_size)\n",
    "word_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the of and a\n"
     ]
    }
   ],
   "source": [
    "print(nlp.vocab.strings[501], nlp.vocab.strings[510], nlp.vocab.strings[512], nlp.vocab.strings[506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 0 1 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {word_id: i for (i, (word_id, freq)) in enumerate(common_words)}\n",
    "print(len(vocab), vocab[501], vocab[504], vocab[510])\n",
    "oov_word = vocab_size - 1\n",
    "oov_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69135    [339, 4999, 4999, 805, 4999, 3513, 0, 1659, 49...\n",
       "80070    [1446, 29, 590, 4999, 1543, 2134, 1744, 142, 4...\n",
       "72555    [556, 4999, 4, 519, 315, 210, 4999, 11, 2768, ...\n",
       "43318    [4999, 2395, 565, 4999, 4999, 1, 1047, 4999, 9...\n",
       "83414    [443, 716, 368, 4999, 4999, 1, 4999, 4999, 499...\n",
       "Name: words_with_oov, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_words_ids_if_common(words):\n",
    "    return [vocab.get(word, oov_word) for word in words]\n",
    "\n",
    "df['words_with_oov'] = df.apply(lambda row: get_words_ids_if_common(row['words']), axis=1)\n",
    "df['words_with_oov'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribution of words. The longest article has 15K words, the shortest 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23168, 16, 538.72820000000002)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = np.array(list(map(len, df['words'])))\n",
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27391\n",
      "2609\n"
     ]
    }
   ],
   "source": [
    "TEST_DOMAINS =  {\n",
    "    'bloomberg.com',\n",
    "     'breitbart.com',\n",
    "     'c-span.org',\n",
    "     'chicagotribune.com',\n",
    "     'chron.com'\n",
    "}\n",
    "df_train =  df.loc[~df['site'].isin(TEST_DOMAINS)]\n",
    "df_test =  df.loc[df['site'].isin(TEST_DOMAINS)]\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enforce all texts to have the same length, truncating or padding if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 3041, 2039,  177],\n",
       "       [   0,    0,    0, ...,  235,  101,   85],\n",
       "       [   0,    0,    0, ...,  842,    0, 2215],\n",
       "       ..., \n",
       "       [   0,    0,    0, ..., 3111, 4999, 1206],\n",
       "       [   0,    0,    0, ..., 1808, 1134,   20],\n",
       "       [  19,   11, 4999, ..., 1664, 4167,   15]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 1000\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "trn = sequence.pad_sequences(df_train['words_with_oov'], maxlen=seq_len, value=0)\n",
    "test = sequence.pad_sequences(df_test['words_with_oov'], maxlen=seq_len, value=0)\n",
    "\n",
    "trn_tensor = torch.from_numpy(trn).long()\n",
    "test_tensor = torch.from_numpy(test).long()\n",
    "\n",
    "trn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the tensor data for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 6\n",
       " 1\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train_tensor = torch.from_numpy(np.array(df_train['bias']))\n",
    "labels_test_tensor = torch.from_numpy(np.array(df_test['bias']))\n",
    "labels_train_tensor[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Hidden Layer NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleHiddenLayerModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        num_dimensions = 32\n",
    "        self.embedding = nn.Embedding(vocab_size, num_dimensions)\n",
    "        self.fc1 = nn.Linear(seq_len * num_dimensions, 100)\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        self.init()\n",
    "        self.classifier = True\n",
    "\n",
    "    def forward(self, words_ids):\n",
    "        x = self.embedding(words_ids) # x => torch.Size([64, 1000, 32])\n",
    "        x = x.view(x.size(0), -1) # x => torch.Size([64, 16000])\n",
    "        x = self.fc1(x)\n",
    "        if self.classifier:\n",
    "            x = F.relu(x, True)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def init(self):\n",
    "        torch.nn.init.constant(self.fc1.bias, val=0.0)\n",
    "        torch.nn.init.constant(self.fc2.bias, val=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleHiddenLayerModule (\n",
       "  (embedding): Embedding(5000, 32)\n",
       "  (fc1): Linear (32000 -> 100)\n",
       "  (dropout): Dropout (p = 0.7)\n",
       "  (fc2): Linear (100 -> 7)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "model = SingleHiddenLayerModule()\n",
    "\n",
    "def make_trainer(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if(use_cuda):\n",
    "        model.cuda()\n",
    "        criterion.cuda()\n",
    "    trainer = ModuleTrainer(model)\n",
    "    trainer.set_optimizer(optim.Adam, lr=1e-3)\n",
    "    trainer.set_loss(criterion)\n",
    "    trainer.set_initializers([Uniform(module_filter=\"embedding*\", a=-0.05, b=0.05), XavierUniform(module_filter=\"fc*\")])\n",
    "    trainer.set_metrics([CategoricalAccuracy()])\n",
    "\n",
    "    return trainer\n",
    "    \n",
    "trainer = make_trainer(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 429 batches [00:34, 12.50 batches/s, acc=44.05, loss=1.4276, val_acc=45.52, val_loss=1.3247]\n"
     ]
    }
   ],
   "source": [
    "model.classifier = True\n",
    "trainer.fit(trn_tensor, labels_train_tensor, val_data=(test_tensor, labels_test_tensor), \n",
    "            nb_epoch=1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc [ 5.21272518]\n"
     ]
    }
   ],
   "source": [
    "precision = sum(torch.max(trainer.predict(test_tensor).data, 1)[1] == labels_test_tensor).numpy() * 1.0 / len(labels_test_tensor)\n",
    "print(\"Val acc\", 100.0 * precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually verify some articles. The bias for these articles should match the predicted bias below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>bias</th>\n",
       "      <th>docs</th>\n",
       "      <th>words</th>\n",
       "      <th>words_with_oov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80793</th>\n",
       "      <td>80793</td>\n",
       "      <td>2016-07-19T06:34:00.000+03:00</td>\n",
       "      <td>chicagotribune.com</td>\n",
       "      <td>Even at convention, Trump finds it hard to ste...</td>\n",
       "      <td>Even at convention, Trump finds it hard to ste...</td>\n",
       "      <td>http://www.chicagotribune.com/news/nationworld...</td>\n",
       "      <td>2</td>\n",
       "      <td>(Even, at, convention, ,, Trump, finds, it, ha...</td>\n",
       "      <td>[1285, 584, 7553, 576246, 5370, 519, 954, 504,...</td>\n",
       "      <td>[830, 15, 1525, 30, 3442, 14, 451, 1, 1112, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36451</th>\n",
       "      <td>36451</td>\n",
       "      <td>2016-02-23T09:12:00.000+02:00</td>\n",
       "      <td>chron.com</td>\n",
       "      <td>Close Image 1 of 4 A man holds his smart phone...</td>\n",
       "      <td>Chinese phones go global after pushing aside A...</td>\n",
       "      <td>http://www.chron.com/business/technology/artic...</td>\n",
       "      <td>2</td>\n",
       "      <td>(Close, Image, 1, of, 4, A, man, holds, his, s...</td>\n",
       "      <td>[544954, 580713, 510, 688, 852, 4138, 553, 174...</td>\n",
       "      <td>[2998, 546, 2, 37, 210, 2360, 24, 2612, 965, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91691</th>\n",
       "      <td>91691</td>\n",
       "      <td>2015-08-28T03:00:00.000+03:00</td>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td>Type of Data * Update Needed * \\nAll data chan...</td>\n",
       "      <td>AMANA INC (2402:Tokyo): Ownership &amp; Shareholde...</td>\n",
       "      <td>http://www.bloomberg.com/research/stocks/owner...</td>\n",
       "      <td>2</td>\n",
       "      <td>(Type, of, Data, *, Update, Needed, *, \\n, All...</td>\n",
       "      <td>[755732, 510, 663156, 156974, 593302, 1125, 16...</td>\n",
       "      <td>[4999, 2, 4500, 4999, 4999, 426, 459, 994, 162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92490</th>\n",
       "      <td>92490</td>\n",
       "      <td>2015-08-28T03:00:00.000+03:00</td>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td>Financial Statements Ratios Pensions &amp; Options...</td>\n",
       "      <td>BEIJING CHIEFTAIN CONTROL -A (300430:Shenzhen)...</td>\n",
       "      <td>http://www.bloomberg.com/research/stocks/finan...</td>\n",
       "      <td>2</td>\n",
       "      <td>(Financial, Statements, Ratios, Pensions, &amp;, O...</td>\n",
       "      <td>[36837, 665381, 487729, 164756, 435163, 224463...</td>\n",
       "      <td>[1692, 4999, 4999, 4999, 4999, 4735, 4999, 169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92081</th>\n",
       "      <td>92081</td>\n",
       "      <td>2015-08-17T01:30:00.000+03:00</td>\n",
       "      <td>chron.com</td>\n",
       "      <td>gallery_overlay_open_thumbs|article-gallery-64...</td>\n",
       "      <td>21st Dream Cruise makes its way up Woodward - ...</td>\n",
       "      <td>http://www.chron.com/cars/article/21st-Dream-C...</td>\n",
       "      <td>2</td>\n",
       "      <td>(gallery_overlay_open_thumbs|article, -, galle...</td>\n",
       "      <td>[794738, 794740, 794742, 580713, 510, 749899, ...</td>\n",
       "      <td>[4999, 4999, 4999, 546, 2, 4999, 1473, 300, 39...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                           date                site  \\\n",
       "80793       80793  2016-07-19T06:34:00.000+03:00  chicagotribune.com   \n",
       "36451       36451  2016-02-23T09:12:00.000+02:00           chron.com   \n",
       "91691       91691  2015-08-28T03:00:00.000+03:00       bloomberg.com   \n",
       "92490       92490  2015-08-28T03:00:00.000+03:00       bloomberg.com   \n",
       "92081       92081  2015-08-17T01:30:00.000+03:00           chron.com   \n",
       "\n",
       "                                                    text  \\\n",
       "80793  Even at convention, Trump finds it hard to ste...   \n",
       "36451  Close Image 1 of 4 A man holds his smart phone...   \n",
       "91691  Type of Data * Update Needed * \\nAll data chan...   \n",
       "92490  Financial Statements Ratios Pensions & Options...   \n",
       "92081  gallery_overlay_open_thumbs|article-gallery-64...   \n",
       "\n",
       "                                                   title  \\\n",
       "80793  Even at convention, Trump finds it hard to ste...   \n",
       "36451  Chinese phones go global after pushing aside A...   \n",
       "91691  AMANA INC (2402:Tokyo): Ownership & Shareholde...   \n",
       "92490  BEIJING CHIEFTAIN CONTROL -A (300430:Shenzhen)...   \n",
       "92081  21st Dream Cruise makes its way up Woodward - ...   \n",
       "\n",
       "                                                     url  bias  \\\n",
       "80793  http://www.chicagotribune.com/news/nationworld...     2   \n",
       "36451  http://www.chron.com/business/technology/artic...     2   \n",
       "91691  http://www.bloomberg.com/research/stocks/owner...     2   \n",
       "92490  http://www.bloomberg.com/research/stocks/finan...     2   \n",
       "92081  http://www.chron.com/cars/article/21st-Dream-C...     2   \n",
       "\n",
       "                                                    docs  \\\n",
       "80793  (Even, at, convention, ,, Trump, finds, it, ha...   \n",
       "36451  (Close, Image, 1, of, 4, A, man, holds, his, s...   \n",
       "91691  (Type, of, Data, *, Update, Needed, *, \\n, All...   \n",
       "92490  (Financial, Statements, Ratios, Pensions, &, O...   \n",
       "92081  (gallery_overlay_open_thumbs|article, -, galle...   \n",
       "\n",
       "                                                   words  \\\n",
       "80793  [1285, 584, 7553, 576246, 5370, 519, 954, 504,...   \n",
       "36451  [544954, 580713, 510, 688, 852, 4138, 553, 174...   \n",
       "91691  [755732, 510, 663156, 156974, 593302, 1125, 16...   \n",
       "92490  [36837, 665381, 487729, 164756, 435163, 224463...   \n",
       "92081  [794738, 794740, 794742, 580713, 510, 749899, ...   \n",
       "\n",
       "                                          words_with_oov  \n",
       "80793  [830, 15, 1525, 30, 3442, 14, 451, 1, 1112, 30...  \n",
       "36451  [2998, 546, 2, 37, 210, 2360, 24, 2612, 965, 1...  \n",
       "91691  [4999, 2, 4500, 4999, 4999, 426, 459, 994, 162...  \n",
       "92490  [1692, 4999, 4999, 4999, 4999, 4735, 4999, 169...  \n",
       "92081  [4999, 4999, 4999, 546, 2, 4999, 1473, 300, 39...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df_test.sample(5)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   24   814     4  ...    248    25  2072\n",
      " 4999     5   461  ...    253  4490   177\n",
      "    0     0     0  ...   1224    85    15\n",
      "    0     0     0  ...   4999  4816  4999\n",
      " 4999  4999   737  ...    138    54  4999\n",
      "[torch.LongTensor of size 5x1000]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 4\n",
       " 2\n",
       "[torch.LongTensor of size 5x1]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier = True\n",
    "predictor = ModuleTrainer(model)\n",
    "sample = sequence.pad_sequences(df_sample['words_with_oov'], maxlen=seq_len, value=0)\n",
    "sample_tensor = torch.from_numpy(sample).long()\n",
    "print(sample_tensor)\n",
    "torch.max(predictor.predict(sample_tensor), 1)[1]\n",
    "# trainer.predict(sample_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.9039  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  4.0931  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  1.7655  ...   0.0000  0.0000  0.0000\n",
       "          ...             ⋱             ...          \n",
       " 0.0000  0.0649  0.0000  ...   0.0000  0.0000  0.3370\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  1.1352  ...   0.0000  0.0000  2.7516\n",
       "[torch.FloatTensor of size 27391x100]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier = False\n",
    "article_vectors_var = trainer.predict(trn_tensor)\n",
    "article_vectors = article_vectors_var.data.numpy()\n",
    "article_vectors_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_vectors = []\n",
    "labels = []\n",
    "for site in df_train['site'].unique():\n",
    "    site_indexes = np.where(df_train[\"site\"] == site)[0]\n",
    "    if len(site_indexes) > 0:\n",
    "        site_vector = np.mean(article_vectors[site_indexes, :], axis=0)\n",
    "        site_vectors.append(site_vector)\n",
    "        labels.append(site)\n",
    "site_vectors = np.array(site_vectors)\n",
    "site_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_model = TSNE(n_components=2, random_state=0)\n",
    "# np.set_printoptions(suppress=True)\n",
    "site_vectors_2_dim = tsne_model.fit_transform(site_vectors)\n",
    "X_proj = site_vectors_2_dim[:, 0]\n",
    "Y_proj = site_vectors_2_dim[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from plotly.graph_objs import Bar, Scatter, Figure, Layout, XAxis, YAxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "size": 10
         },
         "mode": "markers+text",
         "text": [
          "motherjones.com",
          "rightwingnews.com",
          "rawstory.com",
          "wsj.com",
          "propublica.org",
          "100percentfedup.com",
          "louderwithcrowder.com",
          "occupydemocrats.com",
          "youngcons.com",
          "economist.com",
          "latimes.com",
          "dailykos.com",
          "theblaze.com",
          "cnn.com",
          "democracynow.org",
          "mediamatters.org",
          "nydailynews.com",
          "washingtonexaminer.com",
          "thinkprogress.org",
          "afp.com",
          "seattletimes.com",
          "westernjournalism.com",
          "forbes.com",
          "ijr.com",
          "allenbwest.com",
          "nypost.com",
          "azcentral.com",
          "nytimes.com",
          "nj.com",
          "ft.com",
          "politicususa.com",
          "townhall.com",
          "thenewcivilrightsmovement.com",
          "washingtonpost.com",
          "talkingpointsmemo.com",
          "slate.com",
          "usatoday.com",
          "sfchronicle.com",
          "thenation.com",
          "dailywire.com",
          "reuters.com",
          "redstate.com",
          "dailycaller.com",
          "bizpacreview.com",
          "apnews.com",
          "thegatewaypundit.com",
          "thefederalistpapers.org",
          "conservativetribune.com",
          "dallasnews.com",
          "judicialwatch.org",
          "bbc.com",
          "truthfeed.com",
          "oppositionreport.com",
          "freedomdaily.com",
          "conservative101.com",
          "mrctv.org",
          "usherald.com"
         ],
         "textposition": "top",
         "type": "scatter",
         "x": [
          -18.987448939410868,
          81.29046480301031,
          102.32225868072253,
          123.86190102775079,
          -49.13710766308161,
          -57.1856690428685,
          -97.30881602537522,
          17.098102220137044,
          130.31749491010078,
          -123.71491488978967,
          -44.314518426942385,
          65.7615434243891,
          84.06319722801044,
          286.2958971545413,
          54.67268198035675,
          -85.88625687737394,
          14.059849191477037,
          9.451641677398994,
          -59.0500172472393,
          -21.49402672726808,
          161.2456540362419,
          40.789335047597966,
          -6.259165511343178,
          -108.82237633386585,
          -11.787002874656102,
          65.78778766515056,
          -118.07389197756792,
          -23.797671702533925,
          41.63328273008763,
          73.39796231204635,
          -33.31369251361393,
          40.81462366433992,
          52.58156981375103,
          -87.53796659793484,
          -53.064027351123045,
          -25.739779619465338,
          -358.7201202766512,
          -36.23479109641869,
          -74.01349109007242,
          -53.22385800658097,
          10.807885322133561,
          27.542845960668984,
          -84.68879640615035,
          4.383305836697669,
          -61.503921093555256,
          39.10982855745504,
          19.178231006397343,
          110.93579325557604,
          12.260420389398169,
          17.624453082026896,
          115.01408229385778,
          -19.09457388737263,
          -94.29855915305414,
          39.942539911865595,
          82.75247393080481,
          59.07368615152674,
          -168.0095976512416
         ],
         "y": [
          78.00492608554184,
          -60.46648628732976,
          76.3902897634447,
          -1.4503854116074626,
          -15.791500214293295,
          -110.37067907996389,
          -77.97404692195694,
          -61.69508410417453,
          -57.44605306804105,
          36.72827950024422,
          10.609051868297598,
          -101.23394247369832,
          15.60871445221858,
          -199.0485265641066,
          73.54733558485903,
          -38.866321248476126,
          -25.649745668597884,
          18.491395862265605,
          -72.67350745235329,
          -25.003397702760843,
          -27.74772839420494,
          101.94908402836377,
          -2.9080447503041817,
          0.8905659404508466,
          -76.50319341907085,
          -35.05792239552171,
          -35.99044652596991,
          23.561977073888656,
          7.6131584450932435,
          -8.958931520240817,
          50.34846129876751,
          -18.189495858086406,
          -70.66221915961813,
          57.64752051832464,
          -45.35775904691434,
          -51.24196915121079,
          182.4790913819162,
          120.08094320251826,
          -9.768444057658353,
          70.90893623617387,
          118.69803638456325,
          37.2196408857684,
          20.7655283295533,
          52.83021028064823,
          35.564900216389816,
          -129.12489983478957,
          77.3408585966114,
          -35.29304467119471,
          -95.10283079309734,
          217.4896155378722,
          33.251723872719076,
          -120.06871662154161,
          98.15634482198556,
          -47.13020126906388,
          51.6882938055703,
          32.1070517600531,
          1.2073020584133312
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 700,
        "width": 1000
       }
      },
      "text/html": [
       "<div id=\"e3508933-1516-4252-b9d3-4773ab631a64\" style=\"height: 700px; width: 1000px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e3508933-1516-4252-b9d3-4773ab631a64\", [{\"textposition\": \"top\", \"mode\": \"markers+text\", \"marker\": {\"size\": 10}, \"text\": [\"motherjones.com\", \"rightwingnews.com\", \"rawstory.com\", \"wsj.com\", \"propublica.org\", \"100percentfedup.com\", \"louderwithcrowder.com\", \"occupydemocrats.com\", \"youngcons.com\", \"economist.com\", \"latimes.com\", \"dailykos.com\", \"theblaze.com\", \"cnn.com\", \"democracynow.org\", \"mediamatters.org\", \"nydailynews.com\", \"washingtonexaminer.com\", \"thinkprogress.org\", \"afp.com\", \"seattletimes.com\", \"westernjournalism.com\", \"forbes.com\", \"ijr.com\", \"allenbwest.com\", \"nypost.com\", \"azcentral.com\", \"nytimes.com\", \"nj.com\", \"ft.com\", \"politicususa.com\", \"townhall.com\", \"thenewcivilrightsmovement.com\", \"washingtonpost.com\", \"talkingpointsmemo.com\", \"slate.com\", \"usatoday.com\", \"sfchronicle.com\", \"thenation.com\", \"dailywire.com\", \"reuters.com\", \"redstate.com\", \"dailycaller.com\", \"bizpacreview.com\", \"apnews.com\", \"thegatewaypundit.com\", \"thefederalistpapers.org\", \"conservativetribune.com\", \"dallasnews.com\", \"judicialwatch.org\", \"bbc.com\", \"truthfeed.com\", \"oppositionreport.com\", \"freedomdaily.com\", \"conservative101.com\", \"mrctv.org\", \"usherald.com\"], \"y\": [78.00492608554184, -60.46648628732976, 76.3902897634447, -1.4503854116074626, -15.791500214293295, -110.37067907996389, -77.97404692195694, -61.69508410417453, -57.44605306804105, 36.72827950024422, 10.609051868297598, -101.23394247369832, 15.60871445221858, -199.0485265641066, 73.54733558485903, -38.866321248476126, -25.649745668597884, 18.491395862265605, -72.67350745235329, -25.003397702760843, -27.74772839420494, 101.94908402836377, -2.9080447503041817, 0.8905659404508466, -76.50319341907085, -35.05792239552171, -35.99044652596991, 23.561977073888656, 7.6131584450932435, -8.958931520240817, 50.34846129876751, -18.189495858086406, -70.66221915961813, 57.64752051832464, -45.35775904691434, -51.24196915121079, 182.4790913819162, 120.08094320251826, -9.768444057658353, 70.90893623617387, 118.69803638456325, 37.2196408857684, 20.7655283295533, 52.83021028064823, 35.564900216389816, -129.12489983478957, 77.3408585966114, -35.29304467119471, -95.10283079309734, 217.4896155378722, 33.251723872719076, -120.06871662154161, 98.15634482198556, -47.13020126906388, 51.6882938055703, 32.1070517600531, 1.2073020584133312], \"type\": \"scatter\", \"x\": [-18.987448939410868, 81.29046480301031, 102.32225868072253, 123.86190102775079, -49.13710766308161, -57.1856690428685, -97.30881602537522, 17.098102220137044, 130.31749491010078, -123.71491488978967, -44.314518426942385, 65.7615434243891, 84.06319722801044, 286.2958971545413, 54.67268198035675, -85.88625687737394, 14.059849191477037, 9.451641677398994, -59.0500172472393, -21.49402672726808, 161.2456540362419, 40.789335047597966, -6.259165511343178, -108.82237633386585, -11.787002874656102, 65.78778766515056, -118.07389197756792, -23.797671702533925, 41.63328273008763, 73.39796231204635, -33.31369251361393, 40.81462366433992, 52.58156981375103, -87.53796659793484, -53.064027351123045, -25.739779619465338, -358.7201202766512, -36.23479109641869, -74.01349109007242, -53.22385800658097, 10.807885322133561, 27.542845960668984, -84.68879640615035, 4.383305836697669, -61.503921093555256, 39.10982855745504, 19.178231006397343, 110.93579325557604, 12.260420389398169, 17.624453082026896, 115.01408229385778, -19.09457388737263, -94.29855915305414, 39.942539911865595, 82.75247393080481, 59.07368615152674, -168.0095976512416]}], {\"autosize\": false, \"width\": 1000, \"height\": 700}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"e3508933-1516-4252-b9d3-4773ab631a64\" style=\"height: 700px; width: 1000px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e3508933-1516-4252-b9d3-4773ab631a64\", [{\"textposition\": \"top\", \"mode\": \"markers+text\", \"marker\": {\"size\": 10}, \"text\": [\"motherjones.com\", \"rightwingnews.com\", \"rawstory.com\", \"wsj.com\", \"propublica.org\", \"100percentfedup.com\", \"louderwithcrowder.com\", \"occupydemocrats.com\", \"youngcons.com\", \"economist.com\", \"latimes.com\", \"dailykos.com\", \"theblaze.com\", \"cnn.com\", \"democracynow.org\", \"mediamatters.org\", \"nydailynews.com\", \"washingtonexaminer.com\", \"thinkprogress.org\", \"afp.com\", \"seattletimes.com\", \"westernjournalism.com\", \"forbes.com\", \"ijr.com\", \"allenbwest.com\", \"nypost.com\", \"azcentral.com\", \"nytimes.com\", \"nj.com\", \"ft.com\", \"politicususa.com\", \"townhall.com\", \"thenewcivilrightsmovement.com\", \"washingtonpost.com\", \"talkingpointsmemo.com\", \"slate.com\", \"usatoday.com\", \"sfchronicle.com\", \"thenation.com\", \"dailywire.com\", \"reuters.com\", \"redstate.com\", \"dailycaller.com\", \"bizpacreview.com\", \"apnews.com\", \"thegatewaypundit.com\", \"thefederalistpapers.org\", \"conservativetribune.com\", \"dallasnews.com\", \"judicialwatch.org\", \"bbc.com\", \"truthfeed.com\", \"oppositionreport.com\", \"freedomdaily.com\", \"conservative101.com\", \"mrctv.org\", \"usherald.com\"], \"y\": [78.00492608554184, -60.46648628732976, 76.3902897634447, -1.4503854116074626, -15.791500214293295, -110.37067907996389, -77.97404692195694, -61.69508410417453, -57.44605306804105, 36.72827950024422, 10.609051868297598, -101.23394247369832, 15.60871445221858, -199.0485265641066, 73.54733558485903, -38.866321248476126, -25.649745668597884, 18.491395862265605, -72.67350745235329, -25.003397702760843, -27.74772839420494, 101.94908402836377, -2.9080447503041817, 0.8905659404508466, -76.50319341907085, -35.05792239552171, -35.99044652596991, 23.561977073888656, 7.6131584450932435, -8.958931520240817, 50.34846129876751, -18.189495858086406, -70.66221915961813, 57.64752051832464, -45.35775904691434, -51.24196915121079, 182.4790913819162, 120.08094320251826, -9.768444057658353, 70.90893623617387, 118.69803638456325, 37.2196408857684, 20.7655283295533, 52.83021028064823, 35.564900216389816, -129.12489983478957, 77.3408585966114, -35.29304467119471, -95.10283079309734, 217.4896155378722, 33.251723872719076, -120.06871662154161, 98.15634482198556, -47.13020126906388, 51.6882938055703, 32.1070517600531, 1.2073020584133312], \"type\": \"scatter\", \"x\": [-18.987448939410868, 81.29046480301031, 102.32225868072253, 123.86190102775079, -49.13710766308161, -57.1856690428685, -97.30881602537522, 17.098102220137044, 130.31749491010078, -123.71491488978967, -44.314518426942385, 65.7615434243891, 84.06319722801044, 286.2958971545413, 54.67268198035675, -85.88625687737394, 14.059849191477037, 9.451641677398994, -59.0500172472393, -21.49402672726808, 161.2456540362419, 40.789335047597966, -6.259165511343178, -108.82237633386585, -11.787002874656102, 65.78778766515056, -118.07389197756792, -23.797671702533925, 41.63328273008763, 73.39796231204635, -33.31369251361393, 40.81462366433992, 52.58156981375103, -87.53796659793484, -53.064027351123045, -25.739779619465338, -358.7201202766512, -36.23479109641869, -74.01349109007242, -53.22385800658097, 10.807885322133561, 27.542845960668984, -84.68879640615035, 4.383305836697669, -61.503921093555256, 39.10982855745504, 19.178231006397343, 110.93579325557604, 12.260420389398169, 17.624453082026896, 115.01408229385778, -19.09457388737263, -94.29855915305414, 39.942539911865595, 82.75247393080481, 59.07368615152674, -168.0095976512416]}], {\"autosize\": false, \"width\": 1000, \"height\": 700}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace = Scatter(x=X_proj, y=Y_proj, mode='markers+text', text=labels, textposition='top',  marker=dict(size=10))\n",
    "iplot({\n",
    "    'data': [trace],\n",
    "    'layout': Layout(\n",
    "        #xaxis=XAxis(title='Left vs Right'), \n",
    "        #yaxis=YAxis(title='Biased vs Factual'),\n",
    "        autosize=False,\n",
    "        width=1000,\n",
    "        height=700)},\n",
    "    show_link=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
