{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigo/Libs/torchsample/torchsample/datasets.py:16: UserWarning: Cant import nibabel.. Cant load brain images\n",
      "  warnings.warn('Cant import nibabel.. Cant load brain images')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "from torchsample.initializers import XavierUniform, Uniform\n",
    "from torchsample.modules import ModuleTrainer\n",
    "from torchsample.metrics import CategoricalAccuracy\n",
    "\n",
    "%aimport torchsample.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103262\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/source/newsclust.csv\")\n",
    "df = df.query(\"site != 'cbn.com'\")\n",
    "print(len(df))\n",
    "# df = df.sample(3000)\n",
    "df = df.sample(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42862</th>\n",
       "      <td>42862</td>\n",
       "      <td>2015-06-16T03:00:00.000+03:00</td>\n",
       "      <td>chron.com</td>\n",
       "      <td>Governor signs bill on $25 withdrawal for welf...</td>\n",
       "      <td>Governor signs bill on $25 withdrawal for welf...</td>\n",
       "      <td>http://www.chron.com/news/article/Governor-sig...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75576</th>\n",
       "      <td>75576</td>\n",
       "      <td>2016-09-22T03:00:00.000+03:00</td>\n",
       "      <td>wsj.com</td>\n",
       "      <td>When we wrote last month that Margrethe Vestag...</td>\n",
       "      <td>Vestager Gets Vindictive</td>\n",
       "      <td>http://online.wsj.com/articles/vestager-gets-v...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                           date       site  \\\n",
       "42862       42862  2015-06-16T03:00:00.000+03:00  chron.com   \n",
       "75576       75576  2016-09-22T03:00:00.000+03:00    wsj.com   \n",
       "\n",
       "                                                    text  \\\n",
       "42862  Governor signs bill on $25 withdrawal for welf...   \n",
       "75576  When we wrote last month that Margrethe Vestag...   \n",
       "\n",
       "                                                   title  \\\n",
       "42862  Governor signs bill on $25 withdrawal for welf...   \n",
       "75576                           Vestager Gets Vindictive   \n",
       "\n",
       "                                                     url  bias  \n",
       "42862  http://www.chron.com/news/article/Governor-sig...     2  \n",
       "75576  http://online.wsj.com/articles/vestager-gets-v...     4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bias import Bias\n",
    "\n",
    "num_classes = 7\n",
    "df['bias'] = df.apply(lambda row: Bias.get_bias_for_domain(row['site']).value, axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "nlp.pipeline = []\n",
    "\n",
    "def tokenize_text(texts):\n",
    "    docs = [doc for doc in nlp.pipe(texts, batch_size=500, n_threads=8)]\n",
    "    return docs\n",
    "\n",
    "def is_invalid_token(token):\n",
    "    return token.is_punct or token.is_space or token.like_url or token.like_num or token.is_digit\n",
    "\n",
    "def get_words_for_docs(docs):\n",
    "    return [get_words_ids(doc) for doc in docs]\n",
    "\n",
    "def get_words_ids(doc):\n",
    "    return [token.orth for token in doc if not is_invalid_token(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['docs'] = tokenize_text(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>bias</th>\n",
       "      <th>docs</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42862</th>\n",
       "      <td>42862</td>\n",
       "      <td>2015-06-16T03:00:00.000+03:00</td>\n",
       "      <td>chron.com</td>\n",
       "      <td>Governor signs bill on $25 withdrawal for welf...</td>\n",
       "      <td>Governor signs bill on $25 withdrawal for welf...</td>\n",
       "      <td>http://www.chron.com/news/article/Governor-sig...</td>\n",
       "      <td>2</td>\n",
       "      <td>(Governor, signs, bill, on, $, 25, withdrawal,...</td>\n",
       "      <td>[5916, 3245, 1734, 542, 448, 447933, 531, 3549...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                           date       site  \\\n",
       "42862       42862  2015-06-16T03:00:00.000+03:00  chron.com   \n",
       "\n",
       "                                                    text  \\\n",
       "42862  Governor signs bill on $25 withdrawal for welf...   \n",
       "\n",
       "                                                   title  \\\n",
       "42862  Governor signs bill on $25 withdrawal for welf...   \n",
       "\n",
       "                                                     url  bias  \\\n",
       "42862  http://www.chron.com/news/article/Governor-sig...     2   \n",
       "\n",
       "                                                    docs  \\\n",
       "42862  (Governor, signs, bill, on, $, 25, withdrawal,...   \n",
       "\n",
       "                                                   words  \n",
       "42862  [5916, 3245, 1734, 542, 448, 447933, 531, 3549...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words'] = get_words_for_docs(df['docs'])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(501, 764843), (504, 422008), (510, 382700), (506, 338671), (512, 338549)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab_size = 5000\n",
    "\n",
    "def flatten(l):\n",
    "    flat_list = [item for sublist in l for item in sublist]\n",
    "    return flat_list\n",
    "\n",
    "word_freq = Counter(flatten(df['words']))\n",
    "common_words = word_freq.most_common(vocab_size)\n",
    "word_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the of and a\n"
     ]
    }
   ],
   "source": [
    "print(nlp.vocab.strings[501], nlp.vocab.strings[510], nlp.vocab.strings[512], nlp.vocab.strings[506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 0 1 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {word_id: i for (i, (word_id, freq)) in enumerate(common_words)}\n",
    "print(len(vocab), vocab[501], vocab[504], vocab[510])\n",
    "oov_word = vocab_size - 1\n",
    "oov_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42862    [1764, 1754, 410, 9, 79, 4999, 8, 3318, 4999, ...\n",
       "75576    [243, 43, 378, 104, 325, 6, 4999, 4999, 12, 24...\n",
       "36282    [4999, 4, 0, 4999, 318, 2, 181, 3152, 4999, 49...\n",
       "1020     [4999, 4999, 2, 53, 4325, 356, 91, 1, 4999, 13...\n",
       "20457    [258, 4999, 1262, 2393, 651, 874, 178, 249, 49...\n",
       "Name: words_with_oov, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_words_ids_if_common(words):\n",
    "    return [vocab.get(word, oov_word) for word in words]\n",
    "\n",
    "df['words_with_oov'] = df.apply(lambda row: get_words_ids_if_common(row['words']), axis=1)\n",
    "df['words_with_oov'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15046, 21, 538.34870000000001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = np.array(list(map(len, df['words'])))\n",
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27383\n",
      "2617\n"
     ]
    }
   ],
   "source": [
    "TEST_DOMAINS =  {\n",
    "    'bloomberg.com',\n",
    "     'breitbart.com',\n",
    "     'c-span.org',\n",
    "     'chicagotribune.com',\n",
    "     'chron.com'\n",
    "}\n",
    "df_train =  df.loc[~df['site'].isin(TEST_DOMAINS)]\n",
    "df_test =  df.loc[df['site'].isin(TEST_DOMAINS)]\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   38, 1391,   59],\n",
       "       [   0,    0,    0, ...,  153,    0, 1079],\n",
       "       [   0,    0,    0, ...,   31, 4999,  626],\n",
       "       ..., \n",
       "       [   0,    0,    0, ...,   71,  456,  604],\n",
       "       [   0,    0,    0, ..., 4999, 1591, 4999],\n",
       "       [   0,    0,    0, ..., 4999,  453,   29]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 1000\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "trn = sequence.pad_sequences(df_train['words_with_oov'], maxlen=seq_len, value=0)\n",
    "test = sequence.pad_sequences(df_test['words_with_oov'], maxlen=seq_len, value=0)\n",
    "\n",
    "trn_tensor = torch.from_numpy(trn).long()\n",
    "test_tensor = torch.from_numpy(test).long()\n",
    "\n",
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 4\n",
       " 3\n",
       " 2\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train_tensor = torch.from_numpy(np.array(df_train['bias']))\n",
    "labels_test_tensor = torch.from_numpy(np.array(df_test['bias']))\n",
    "labels_train_tensor[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleHiddenLayerModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        num_dimensions = 32\n",
    "        self.embedding = nn.Embedding(vocab_size, num_dimensions)\n",
    "        self.fc1 = nn.Linear(seq_len * num_dimensions, 100)\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        self.init()\n",
    "\n",
    "    def forward(self, words_ids):\n",
    "        x = self.embedding(words_ids) # x => torch.Size([64, 1000, 32])\n",
    "        x = x.view(x.size(0), -1) # x => torch.Size([64, 16000])\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x, True)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        result = x\n",
    "        return result\n",
    "    \n",
    "    def init(self):\n",
    "        torch.nn.init.constant(self.fc1.bias, val=0.0)\n",
    "        torch.nn.init.constant(self.fc2.bias, val=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleHiddenLayerModule (\n",
       "  (embedding): Embedding(5000, 32)\n",
       "  (fc1): Linear (32000 -> 100)\n",
       "  (dropout): Dropout (p = 0.7)\n",
       "  (fc2): Linear (100 -> 7)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = SingleHiddenLayerModule()\n",
    "if(use_cuda):\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "trainer = ModuleTrainer(model)\n",
    "trainer.set_optimizer(optim.Adam, lr=1e-3)\n",
    "trainer.set_loss(criterion)\n",
    "trainer.set_initializers([Uniform(module_filter=\"embedding*\", a=-0.05, b=0.05), XavierUniform(module_filter=\"fc*\")])\n",
    "trainer.set_metrics([CategoricalAccuracy()])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 429 batches [00:37, 11.34 batches/s, val_loss=1.4235, loss=1.4448, val_acc=44.17, acc=43.22]\n",
      "Epoch 2/10: 429 batches [00:34,  5.75 batches/s, val_loss=1.4370, loss=0.7257, val_acc=71.67, acc=73.90]\n",
      "Epoch 3/10: 429 batches [00:34,  5.77 batches/s, val_loss=1.4744, loss=0.3984, val_acc=82.65, acc=86.34]\n",
      "Epoch 4/10: 429 batches [00:34, 12.54 batches/s, val_loss=1.9989, loss=0.2410, val_acc=87.62, acc=92.02]\n",
      "Epoch 5/10: 429 batches [00:34, 12.51 batches/s, val_loss=2.2060, loss=0.1636, val_acc=90.18, acc=94.73]\n",
      "Epoch 6/10: 429 batches [00:34,  5.71 batches/s, val_loss=2.5539, loss=0.1175, val_acc=90.99, acc=96.18]\n",
      "Epoch 7/10:  63%|██████▎   | 269/428 [00:21<00:13, 12.17 batches/s, loss=0.0900, acc=97.08]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f29859605a19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer.fit(trn_tensor, labels_train_tensor, val_data=(test_tensor, labels_test_tensor), \n\u001b[0;32m----> 2\u001b[0;31m             nb_epoch=10, batch_size=batch_size, shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/Users/rodrigo/Libs/torchsample/torchsample/modules/module_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, targets, val_data, nb_epoch, batch_size, shuffle, cuda_device, verbose)\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0;31m# backward pass and optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rodrigo/Libs/pytorch/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit(trn_tensor, labels_train_tensor, val_data=(test_tensor, labels_test_tensor), \n",
    "            nb_epoch=10, batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
